# 07-集群管理与高可用

## 本章概述

本章深入剖析Elasticsearch的集群管理机制和高可用设计，重点解决以下问题：
- **问题1**：ES集群有哪些节点类型？各自的职责是什么？
- **问题2**：Master选举机制是如何工作的？
- **问题3**：什么是脑裂？如何避免？
- **问题4**：如何监控集群健康状态？
- **问题5**：集群如何扩容和缩容？

---

## 问题1：ES集群有哪些节点类型？各自的职责是什么?

### 1.1 节点类型概览

```
ES节点类型（按职责划分）：
1. Master Node（主节点）
2. Data Node（数据节点）
3. Coordinating Node（协调节点）
4. Ingest Node（预处理节点）
5. Machine Learning Node（机器学习节点）
6. Transform Node（转换节点）
```

### 1.2 Master Node（主节点）

#### 职责

```
核心职责：
1. 集群元数据管理
   - 索引的创建和删除
   - 节点的加入和离开
   - 分片的分配和迁移

2. 集群状态维护
   - 维护cluster state
   - 将cluster state广播到所有节点

3. 分片分配决策
   - 决定分片分配到哪个节点
   - 分片的重新平衡

注意：
- Master节点不处理数据写入和查询请求
- 只负责集群管理工作
```

#### 配置

```yaml
# elasticsearch.yml

# 专用Master节点（推荐生产环境）
node.master: true
node.data: false
node.ingest: false
node.ml: false

# 说明：
# - 只承担Master职责
# - 不存储数据
# - 不处理查询请求
# - 资源需求低，稳定性高
```

#### Master节点数量建议

```
推荐配置：
- 小集群（< 10节点）：3个Master候选节点
- 中集群（10-50节点）：3个Master候选节点
- 大集群（> 50节点）：5个Master候选节点

为什么是奇数？
- Master选举需要过半数投票
- 奇数可以避免平票
- 3个节点：容忍1个故障
- 5个节点：容忍2个故障

为什么不是越多越好？
- Master节点需要同步cluster state
- 节点越多，同步开销越大
- 3-5个已经足够
```

### 1.3 Data Node（数据节点）

#### 职责

```
核心职责：
1. 存储数据
   - 存储分片数据
   - 维护倒排索引

2. 执行数据操作
   - 文档的CRUD操作
   - 搜索和聚合操作

3. 分片管理
   - 分片的创建和删除
   - 分片的合并和优化

特点：
- 资源消耗大（CPU、内存、磁盘、IO）
- 是集群的主要工作节点
```

#### 配置

```yaml
# elasticsearch.yml

# 专用Data节点
node.master: false
node.data: true
node.ingest: false
node.ml: false

# 数据节点类型（ES 7.9+）
node.roles: [ data ]

# 或者更细粒度的数据节点类型：
# node.roles: [ data_content ]    # 内容数据节点
# node.roles: [ data_hot ]        # 热数据节点
# node.roles: [ data_warm ]       # 温数据节点
# node.roles: [ data_cold ]       # 冷数据节点
# node.roles: [ data_frozen ]     # 冻结数据节点
```

#### 数据节点分层（ES 7.10+）

```
数据生命周期管理（ILM）：

Hot Tier（热层）：
- 存储最新、最活跃的数据
- 高性能硬件（SSD）
- 频繁写入和查询

Warm Tier（温层）：
- 存储不再更新但仍需查询的数据
- 中等性能硬件
- 只读，查询频率降低

Cold Tier（冷层）：
- 存储很少查询的历史数据
- 低成本硬件（HDD）
- 只读，查询频率很低

Frozen Tier（冻结层）：
- 存储归档数据
- 使用快照存储
- 查询时从快照恢复
```

**配置示例**：
```yaml
# Hot节点
node.roles: [ data_hot, data_content ]

# Warm节点
node.roles: [ data_warm ]

# Cold节点
node.roles: [ data_cold ]
```

### 1.4 Coordinating Node（协调节点）

#### 职责

```
核心职责：
1. 请求路由
   - 接收客户端请求
   - 将请求路由到相应的数据节点

2. 结果聚合
   - 收集各数据节点的结果
   - 合并、排序、聚合
   - 返回给客户端

3. 负载均衡
   - 分发请求到不同的分片
   - 避免单个节点过载

特点：
- 所有节点默认都是协调节点
- 可以配置专用协调节点
```

#### 配置

```yaml
# elasticsearch.yml

# 专用Coordinating节点
node.master: false
node.data: false
node.ingest: false
node.ml: false

# 或者使用roles（ES 7.9+）
node.roles: [ ]  # 空数组表示只做协调节点

# 适用场景：
# - 大量的搜索请求
# - 复杂的聚合操作
# - 需要专门的节点来处理请求分发和结果合并
```

#### 何时需要专用协调节点？

```
需要专用协调节点的场景：
1. 搜索请求量大
   - QPS > 10000
   - 需要专门的节点处理请求

2. 聚合操作复杂
   - 多层嵌套聚合
   - 需要大量内存合并结果

3. 客户端连接多
   - 大量客户端连接
   - 需要专门的节点处理连接

不需要专用协调节点的场景：
1. 小集群（< 10节点）
2. 请求量不大
3. 聚合操作简单
```

### 1.5 Ingest Node（预处理节点）

#### 职责

```
核心职责：
1. 数据预处理
   - 在数据写入前进行转换
   - 类似Logstash的功能

2. Pipeline处理
   - 执行一系列Processor
   - 例如：字段提取、格式转换、数据增强

常用Processor：
- Set：设置字段值
- Remove：删除字段
- Rename：重命名字段
- Convert：类型转换
- Grok：正则提取
- Date：日期解析
- GeoIP：IP地理位置解析
```

#### 配置

```yaml
# elasticsearch.yml

# 启用Ingest功能
node.ingest: true

# 专用Ingest节点
node.master: false
node.data: false
node.ingest: true
node.ml: false
```

#### Pipeline示例

```json
// 创建Pipeline
PUT _ingest/pipeline/my_pipeline
{
  "description": "解析日志并添加地理位置",
  "processors": [
    {
      "grok": {
        "field": "message",
        "patterns": ["%{IP:client_ip} %{WORD:method} %{URIPATHPARAM:request}"]
      }
    },
    {
      "geoip": {
        "field": "client_ip",
        "target_field": "geo"
      }
    },
    {
      "remove": {
        "field": "message"
      }
    }
  ]
}

// 使用Pipeline写入数据
PUT /logs/_doc/1?pipeline=my_pipeline
{
  "message": "192.168.1.1 GET /index.html"
}

// 结果
{
  "client_ip": "192.168.1.1",
  "method": "GET",
  "request": "/index.html",
  "geo": {
    "country_name": "China",
    "city_name": "Beijing",
    "location": { "lat": 39.9042, "lon": 116.4074 }
  }
}
```

### 1.6 节点类型组合

#### 组合1：小型集群（< 10节点）

```yaml
# 所有节点都是全能节点
node.master: true
node.data: true
node.ingest: true

优点：
- 配置简单
- 资源利用率高

缺点：
- 职责不清晰
- 稳定性一般

适用场景：
- 开发环境
- 测试环境
- 小型生产环境
```

#### 组合2：中型集群（10-50节点）

```
节点规划：
1. 3个专用Master节点
   - node.master: true
   - node.data: false
   - 配置：4核8G

2. N个Data节点
   - node.master: false
   - node.data: true
   - 配置：16核64G，SSD

3. 2个Coordinating节点（可选）
   - node.master: false
   - node.data: false
   - 配置：8核16G

优点：
- 职责分离
- 稳定性高
- 性能好

适用场景：
- 中型生产环境
```

#### 组合3：大型集群（> 50节点）

```
节点规划：
1. 5个专用Master节点
   - node.master: true
   - node.data: false
   - 配置：4核8G

2. N个Data节点（分层）
   - Hot节点：SSD，16核64G
   - Warm节点：SSD，8核32G
   - Cold节点：HDD，4核16G

3. 3-5个Coordinating节点
   - node.master: false
   - node.data: false
   - 配置：16核32G

4. 2个Ingest节点（可选）
   - node.ingest: true
   - 配置：8核16G

优点：
- 高可用
- 高性能
- 可扩展

适用场景：
- 大型生产环境
```

---

## 问题2：Master选举机制是如何工作的？

### 2.1 为什么需要Master选举？

```
问题：如果没有Master选举会怎样？

场景1：多个节点同时认为自己是Master
- 节点A创建索引index1
- 节点B删除索引index1
- 集群状态不一致 ❌

场景2：没有节点是Master
- 无法创建索引
- 无法分配分片
- 集群不可用 ❌

解决方案：Master选举
- 保证同一时刻只有一个Master
- Master故障时自动选举新Master
- 保证集群状态一致性
```

### 2.2 Master选举流程

#### 前置条件

```yaml
# elasticsearch.yml

# Master候选节点配置
node.master: true

# 最小Master候选节点数（ES 7.x之前）
discovery.zen.minimum_master_nodes: 2

# ES 7.x+不需要配置，自动计算
# 公式：(master候选节点数 / 2) + 1
```

#### 选举流程

```
步骤1：节点启动
- 节点启动后，开始发现其他节点
- 使用discovery机制（默认基于Zen Discovery）

步骤2：发现Master候选节点
- 通过seed hosts发现其他节点
- 识别哪些节点是Master候选节点

步骤3：发起选举
- 如果当前没有Master，发起选举
- 每个候选节点投票给自己或其他节点

步骤4：投票规则
- 节点ID较小的优先（确定性）
- 需要获得过半数投票
- 例如：3个候选节点，需要2票

步骤5：选举成功
- 某个节点获得过半数投票
- 该节点成为Master
- 广播cluster state给所有节点

步骤6：选举失败
- 没有节点获得过半数投票
- 重新发起选举
```

#### 选举流程图

```
┌─────────────────────────────────────┐
│ 集群启动 / Master节点故障            │
└──────────────┬──────────────────────┘
               │
               ↓
┌─────────────────────────────────────┐
│ 节点发现（Discovery）                │
│ - 通过seed hosts发现其他节点         │
│ - 识别Master候选节点                 │
└──────────────┬──────────────────────┘
               │
               ↓
┌─────────────────────────────────────┐
│ 发起选举                             │
│ - 每个候选节点投票                   │
│ - 投票给节点ID最小的候选节点         │
└──────────────┬──────────────────────┘
               │
               ↓
┌─────────────────────────────────────┐
│ 统计投票                             │
│ - 是否有节点获得过半数投票？         │
└──────────────┬──────────────────────┘
               │
       ┌───────┴───────┐
       │               │
      是              否
       │               │
       ↓               ↓
┌─────────────┐  ┌─────────────┐
│ 选举成功     │  │ 选举失败     │
│ - 成为Master │  │ - 重新选举   │
│ - 广播状态   │  └─────────────┘
└─────────────┘
```

### 2.3 Master选举示例

#### 场景1：正常选举

```
集群配置：
- 节点A（node-1）：Master候选
- 节点B（node-2）：Master候选
- 节点C（node-3）：Master候选

选举过程：
1. 三个节点启动，发现彼此
2. 发起选举
3. 投票：
   - 节点A投给node-1（自己）
   - 节点B投给node-1（ID最小）
   - 节点C投给node-1（ID最小）
4. 统计：node-1获得3票（过半数）
5. 节点A成为Master ✅
```

#### 场景2：Master故障

```
初始状态：
- 节点A（Master）
- 节点B（候选）
- 节点C（候选）

故障发生：
1. 节点A故障，停止心跳
2. 节点B和C检测到Master失联
3. 发起新一轮选举
4. 投票：
   - 节点B投给node-2（自己）
   - 节点C投给node-2（ID较小）
5. 统计：node-2获得2票（过半数）
6. 节点B成为新Master ✅

恢复时间：
- 通常在几秒内完成
- 期间集群状态为Yellow
- 不影响数据读写（只影响集群管理操作）
```

### 2.4 Quorum机制

#### 什么是Quorum？

```
Quorum（法定人数）：
- 定义：执行操作需要的最小节点数
- 公式：(master候选节点数 / 2) + 1
- 作用：防止脑裂

示例：
- 3个候选节点：Quorum = 2
- 5个候选节点：Quorum = 3
- 7个候选节点：Quorum = 4
```

#### 为什么需要Quorum？

```
场景：网络分区导致集群分裂

没有Quorum机制：
- 分区1：节点A、B（2个节点）
- 分区2：节点C（1个节点）
- 两个分区都选举出Master
- 集群状态不一致 ❌

有Quorum机制：
- 分区1：节点A、B（2个节点，满足Quorum）
  → 可以选举Master ✅
- 分区2：节点C（1个节点，不满足Quorum）
  → 无法选举Master ❌
- 保证只有一个Master
```

### 2.5 ES 7.x的改进

#### 自动计算Quorum

```
ES 7.x之前：
- 需要手动配置discovery.zen.minimum_master_nodes
- 容易配置错误
- 扩容时需要修改配置

ES 7.x+：
- 自动计算Quorum
- 基于cluster.initial_master_nodes
- 首次启动时指定初始Master候选节点
- 后续自动管理
```

#### 配置示例

```yaml
# elasticsearch.yml (ES 7.x+)

# 节点名称
node.name: node-1

# Master候选
node.master: true

# 首次启动时，指定初始Master候选节点
cluster.initial_master_nodes: ["node-1", "node-2", "node-3"]

# 注意：
# - 只在首次启动时需要
# - 集群形成后，会自动管理
# - 新节点加入时，不需要修改此配置
```

---

## 问题3：什么是脑裂？如何避免？

### 3.1 什么是脑裂（Split-Brain）？

#### 定义

```
脑裂（Split-Brain）：
- 集群因网络分区分裂成多个子集群
- 每个子集群都有自己的Master
- 导致集群状态不一致

类比：
- 就像一个人有两个大脑
- 两个大脑做出不同的决策
- 身体不知道听谁的
```

#### 脑裂示例

```
初始状态（3节点集群）：
┌─────────────────────────────┐
│  Master: 节点A               │
│  节点B、节点C                │
└─────────────────────────────┘

网络分区发生：
┌──────────────┐    ┌──────────────┐
│ 分区1         │    │ 分区2         │
│ 节点A（Master）│    │ 节点B、节点C  │
│              │ ❌ │              │
└──────────────┘    └──────────────┘

脑裂结果：
┌──────────────┐    ┌──────────────┐
│ 分区1         │    │ 分区2         │
│ Master: 节点A │    │ Master: 节点B │
│              │    │ 节点C         │
└──────────────┘    └──────────────┘

问题：
- 分区1：节点A认为自己是Master
- 分区2：节点B被选举为Master
- 两个Master同时存在
- 集群状态不一致
```

### 3.2 脑裂的危害

#### 危害1：数据不一致

```
场景：
- 分区1：创建索引index1
- 分区2：创建索引index2
- 网络恢复后：
  - index1和index2的元数据冲突
  - 集群状态混乱

结果：
- 数据丢失
- 索引损坏
- 集群不可用
```

#### 危害2：分片分配混乱

```
场景：
- 分区1：将分片1分配到节点A
- 分区2：将分片1分配到节点B
- 网络恢复后：
  - 分片1有两个副本
  - 不知道哪个是正确的

结果：
- 分片冲突
- 数据不一致
```

### 3.3 如何避免脑裂？

#### 方案1：Quorum机制（核心）

```
原理：
- 要求过半数节点同意才能选举Master
- 网络分区后，只有包含过半数节点的分区能选举Master

示例（3节点集群）：
- Quorum = (3 / 2) + 1 = 2

网络分区：
┌──────────────┐    ┌──────────────┐
│ 分区1（1节点）│    │ 分区2（2节点）│
│ 节点A         │    │ 节点B、节点C  │
│ 不满足Quorum  │    │ 满足Quorum   │
│ 无法选举Master│    │ 可以选举Master│
└──────────────┘    └──────────────┘

结果：
- 只有分区2能选举Master
- 避免脑裂 ✅
```

#### 方案2：奇数个Master候选节点

```
为什么要奇数？

偶数节点（4个）：
- Quorum = (4 / 2) + 1 = 3
- 网络分区：2 vs 2
- 两个分区都不满足Quorum
- 集群不可用 ❌

奇数节点（3个）：
- Quorum = (3 / 2) + 1 = 2
- 网络分区：1 vs 2
- 分区2满足Quorum
- 集群可用 ✅

奇数节点（5个）：
- Quorum = (5 / 2) + 1 = 3
- 网络分区：2 vs 3
- 分区2满足Quorum
- 集群可用 ✅

结论：
- 推荐3或5个Master候选节点
- 不推荐2、4、6等偶数
```

#### 方案3：配置minimum_master_nodes（ES 7.x之前）

```yaml
# elasticsearch.yml (ES 6.x及之前)

# 手动配置最小Master节点数
discovery.zen.minimum_master_nodes: 2

# 公式：(master候选节点数 / 2) + 1
# 3个候选节点：(3 / 2) + 1 = 2
# 5个候选节点：(5 / 2) + 1 = 3

# 注意：
# - ES 7.x+不需要手动配置
# - 自动计算
```

#### 方案4：使用ES 7.x+的自动管理

```yaml
# elasticsearch.yml (ES 7.x+)

# 首次启动时指定初始Master候选节点
cluster.initial_master_nodes: ["node-1", "node-2", "node-3"]

# 优势：
# - 自动计算Quorum
# - 避免配置错误
# - 扩容时不需要修改配置
```

### 3.4 脑裂检测和恢复

#### 检测脑裂

```bash
# 查看集群状态
GET /_cluster/health

# 正常状态
{
  "cluster_name": "my-cluster",
  "status": "green",
  "number_of_nodes": 3,
  "number_of_data_nodes": 3
}

# 脑裂状态（在不同节点查询结果不同）
# 节点A：
{
  "cluster_name": "my-cluster",
  "number_of_nodes": 1  # 只看到自己
}

# 节点B：
{
  "cluster_name": "my-cluster",
  "number_of_nodes": 2  # 看到节点B和C
}
```

#### 恢复脑裂

```
步骤1：停止所有节点
systemctl stop elasticsearch

步骤2：清理集群状态（谨慎操作）
# 备份数据
# 删除data目录下的集群状态文件

步骤3：重新启动集群
# 先启动Master候选节点
# 等待集群形成
# 再启动Data节点

步骤4：验证集群状态
GET /_cluster/health

注意：
- 脑裂恢复可能导致数据丢失
- 建议提前做好备份
- 最好的方案是预防脑裂
```

---

## 问题4：如何监控集群健康状态？

### 4.1 集群健康状态

#### 三种状态

```
Green（绿色）：
- 所有主分片和副本分片都已分配
- 集群完全可用
- 最佳状态 ✅

Yellow（黄色）：
- 所有主分片已分配
- 部分副本分片未分配
- 集群可用，但存在风险 ⚠️
- 常见原因：
  - 副本数 > 节点数
  - 节点故障，副本未恢复

Red（红色）：
- 部分主分片未分配
- 部分数据不可用
- 集群部分功能不可用 ❌
- 常见原因：
  - 节点故障，主分片丢失
  - 磁盘空间不足
  - 分片损坏
```

#### 查看集群健康状态

```bash
# 基本健康检查
GET /_cluster/health

# 响应示例
{
  "cluster_name": "my-cluster",
  "status": "green",
  "timed_out": false,
  "number_of_nodes": 3,
  "number_of_data_nodes": 3,
  "active_primary_shards": 10,
  "active_shards": 20,
  "relocating_shards": 0,
  "initializing_shards": 0,
  "unassigned_shards": 0,
  "delayed_unassigned_shards": 0,
  "number_of_pending_tasks": 0,
  "number_of_in_flight_fetch": 0,
  "task_max_waiting_in_queue_millis": 0,
  "active_shards_percent_as_number": 100.0
}

# 查看索引级别的健康状态
GET /_cluster/health?level=indices

# 查看分片级别的健康状态
GET /_cluster/health?level=shards
```

### 4.2 节点状态监控

#### 查看节点信息

```bash
# 查看所有节点
GET /_cat/nodes?v

# 响应示例
ip            heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name
192.168.1.1   20           50          2   0.5     0.3      0.2      mdi       *      node-1
192.168.1.2   30           60          5   0.8     0.5      0.3      mdi       -      node-2
192.168.1.3   25           55          3   0.6     0.4      0.2      mdi       -      node-3

# 字段说明：
# - heap.percent：JVM堆内存使用率
# - ram.percent：物理内存使用率
# - cpu：CPU使用率
# - load_*：系统负载
# - node.role：节点角色（m=master, d=data, i=ingest）
# - master：是否是当前Master（*表示是）
```

#### 查看节点统计信息

```bash
# 查看所有节点的详细统计
GET /_nodes/stats

# 查看特定节点的统计
GET /_nodes/node-1/stats

# 只查看特定指标
GET /_nodes/stats/jvm,os,process,fs

# 响应示例（部分）
{
  "nodes": {
    "node-1": {
      "jvm": {
        "mem": {
          "heap_used_in_bytes": 2147483648,
          "heap_max_in_bytes": 8589934592,
          "heap_used_percent": 25
        },
        "gc": {
          "collectors": {
            "young": {
              "collection_count": 100,
              "collection_time_in_millis": 1000
            },
            "old": {
              "collection_count": 5,
              "collection_time_in_millis": 500
            }
          }
        }
      },
      "fs": {
        "total": {
          "total_in_bytes": 1099511627776,
          "free_in_bytes": 549755813888,
          "available_in_bytes": 549755813888
        }
      }
    }
  }
}
```

### 4.3 分片状态监控

#### 查看分片分配

```bash
# 查看所有分片
GET /_cat/shards?v

# 响应示例
index    shard prirep state   docs  store ip          node
products 0     p      STARTED 1000  5mb   192.168.1.1 node-1
products 0     r      STARTED 1000  5mb   192.168.1.2 node-2
products 1     p      STARTED 1200  6mb   192.168.1.2 node-2
products 1     r      STARTED 1200  6mb   192.168.1.3 node-3

# 字段说明：
# - shard：分片编号
# - prirep：p=主分片，r=副本分片
# - state：分片状态（STARTED, INITIALIZING, RELOCATING, UNASSIGNED）
# - docs：文档数
# - store：存储大小

# 只查看未分配的分片
GET /_cat/shards?v&h=index,shard,prirep,state,unassigned.reason&s=state

# 查看未分配分片的原因
GET /_cluster/allocation/explain
{
  "index": "products",
  "shard": 0,
  "primary": true
}
```

### 4.4 集群统计信息

```bash
# 查看集群统计
GET /_cluster/stats

# 响应示例（部分）
{
  "cluster_name": "my-cluster",
  "status": "green",
  "indices": {
    "count": 10,
    "shards": {
      "total": 20,
      "primaries": 10,
      "replication": 1.0
    },
    "docs": {
      "count": 1000000,
      "deleted": 5000
    },
    "store": {
      "size_in_bytes": 10737418240
    }
  },
  "nodes": {
    "count": {
      "total": 3,
      "data": 3,
      "master": 3
    },
    "versions": ["7.10.0"],
    "os": {
      "mem": {
        "total_in_bytes": 25769803776,
        "free_in_bytes": 10737418240
      }
    },
    "jvm": {
      "max_uptime_in_millis": 86400000,
      "mem": {
        "heap_used_in_bytes": 6442450944,
        "heap_max_in_bytes": 25769803776
      }
    }
  }
}
```

### 4.5 监控告警

#### 关键指标

```
1. 集群健康状态
   - 指标：cluster.status
   - 告警：status != green
   - 级别：Warning（Yellow）, Critical（Red）

2. 节点可用性
   - 指标：nodes.count
   - 告警：节点数减少
   - 级别：Critical

3. JVM堆内存使用率
   - 指标：jvm.mem.heap_used_percent
   - 告警：> 85%
   - 级别：Warning（85%）, Critical（95%）

4. 磁盘使用率
   - 指标：fs.total.available_in_bytes
   - 告警：可用空间 < 15%
   - 级别：Warning（15%）, Critical（5%）

5. GC频率和时间
   - 指标：jvm.gc.collectors.old.collection_time_in_millis
   - 告警：Old GC时间过长
   - 级别：Warning（> 1s）, Critical（> 5s）

6. 搜索和索引性能
   - 指标：indices.search.query_time_in_millis
   - 告警：查询时间过长
   - 级别：Warning（> 1s）, Critical（> 5s）

7. 未分配分片
   - 指标：unassigned_shards
   - 告警：> 0
   - 级别：Warning
```

#### 监控工具

```
1. Kibana Monitoring
   - ES官方监控工具
   - 可视化界面
   - 实时监控

2. Elasticsearch Watcher
   - ES官方告警工具
   - 基于条件触发告警
   - 支持邮件、Webhook等

3. Prometheus + Grafana
   - 开源监控方案
   - 使用elasticsearch_exporter采集指标
   - Grafana可视化

4. Elastic APM
   - 应用性能监控
   - 监控ES客户端性能
```

#### Watcher告警示例

```json
// 创建Watcher：监控集群健康状态
PUT _watcher/watch/cluster_health_watch
{
  "trigger": {
    "schedule": {
      "interval": "1m"  // 每分钟检查一次
    }
  },
  "input": {
    "http": {
      "request": {
        "host": "localhost",
        "port": 9200,
        "path": "/_cluster/health"
      }
    }
  },
  "condition": {
    "compare": {
      "ctx.payload.status": {
        "not_eq": "green"  // 状态不是green时触发
      }
    }
  },
  "actions": {
    "send_email": {
      "email": {
        "to": "admin@example.com",
        "subject": "ES集群健康状态异常",
        "body": "集群状态：{{ctx.payload.status}}"
      }
    }
  }
}
```

---

## 问题5：集群如何扩容和缩容？

### 5.1 扩容（Scale Out）

#### 场景1：增加Data节点

```
目的：
- 增加存储容量
- 提升查询性能
- 分担负载

步骤：
1. 准备新节点
2. 配置elasticsearch.yml
3. 启动新节点
4. 等待分片重新平衡
```

**配置示例**：
```yaml
# 新节点配置
cluster.name: my-cluster
node.name: node-4
node.master: false
node.data: true

# 发现配置
discovery.seed_hosts: ["192.168.1.1", "192.168.1.2", "192.168.1.3"]
```

**启动节点**：
```bash
# 启动Elasticsearch
systemctl start elasticsearch

# 查看节点是否加入集群
GET /_cat/nodes?v

# 查看分片重新平衡进度
GET /_cat/recovery?v&active_only=true
```

**分片重新平衡**：
```
自动重新平衡：
- ES会自动将部分分片迁移到新节点
- 保持各节点负载均衡
- 过程中不影响服务

监控重新平衡：
GET /_cluster/health

{
  "status": "yellow",  // 重新平衡期间可能是yellow
  "relocating_shards": 5,  // 正在迁移的分片数
  "initializing_shards": 2  // 正在初始化的分片数
}
```

#### 场景2：增加Master候选节点

```
目的：
- 提升集群可用性
- 容忍更多节点故障

步骤：
1. 准备新节点
2. 配置为Master候选节点
3. 启动新节点
4. 新节点自动参与Master选举
```

**配置示例**：
```yaml
# 新Master候选节点配置
cluster.name: my-cluster
node.name: node-4
node.master: true
node.data: false

# 发现配置
discovery.seed_hosts: ["192.168.1.1", "192.168.1.2", "192.168.1.3"]

# 注意：
# - 不需要修改cluster.initial_master_nodes
# - 新节点会自动加入Master选举
```

#### 场景3：增加Coordinating节点

```
目的：
- 分担查询请求压力
- 提升查询性能

步骤：
1. 准备新节点
2. 配置为专用Coordinating节点
3. 启动新节点
4. 配置负载均衡器，将请求分发到Coordinating节点
```

**配置示例**：
```yaml
# 专用Coordinating节点
cluster.name: my-cluster
node.name: coord-1
node.master: false
node.data: false
node.ingest: false

# 或使用roles配置
node.roles: []  # 空数组表示只做协调节点
```

### 5.2 缩容（Scale In）

#### 场景1：移除Data节点

```
目的：
- 减少成本
- 优化资源利用

步骤：
1. 排空节点（将分片迁移到其他节点）
2. 停止节点
3. 从集群中移除节点
```

**排空节点**：
```json
// 设置节点为排空模式
PUT /_cluster/settings
{
  "transient": {
    "cluster.routing.allocation.exclude._name": "node-4"
  }
}

// 监控分片迁移进度
GET /_cat/shards?v&h=index,shard,prirep,state,node&s=node

// 等待node-4上的所有分片迁移完成
// 确认node-4上没有分片后，停止节点
```

**停止节点**：
```bash
# 停止Elasticsearch
systemctl stop elasticsearch

# 从集群中移除节点（可选）
# 节点停止后会自动从集群中移除
```

**清理配置**：
```json
// 清除排空配置
PUT /_cluster/settings
{
  "transient": {
    "cluster.routing.allocation.exclude._name": null
  }
}
```

#### 场景2：移除Master候选节点

```
注意事项：
- 确保剩余Master候选节点数 >= 3
- 不要移除当前的Master节点

步骤：
1. 如果要移除的是当前Master，先触发重新选举
2. 停止节点
3. 从集群中移除节点
```

**触发重新选举**（如果需要）：
```bash
# 停止当前Master节点
# 集群会自动选举新Master

# 或者使用API手动触发（ES 7.x+）
POST /_cluster/voting_config_exclusions?node_names=node-1

# 等待新Master选举完成
GET /_cat/nodes?v&h=name,master

# 清除排除配置
DELETE /_cluster/voting_config_exclusions
```

### 5.3 分片重新平衡配置

#### 控制重新平衡速度

```json
// 调整重新平衡并发数
PUT /_cluster/settings
{
  "transient": {
    "cluster.routing.allocation.cluster_concurrent_rebalance": 2  // 默认2
  }
}

// 调整分片恢复并发数
PUT /_cluster/settings
{
  "transient": {
    "cluster.routing.allocation.node_concurrent_recoveries": 2  // 默认2
  }
}

// 调整恢复速度限制
PUT /_cluster/settings
{
  "transient": {
    "indices.recovery.max_bytes_per_sec": "100mb"  // 默认40mb
  }
}
```

#### 禁用/启用分片分配

```json
// 禁用分片分配（维护时使用）
PUT /_cluster/settings
{
  "transient": {
    "cluster.routing.allocation.enable": "none"
  }
}

// 只允许主分片分配
PUT /_cluster/settings
{
  "transient": {
    "cluster.routing.allocation.enable": "primaries"
  }
}

// 启用所有分片分配
PUT /_cluster/settings
{
  "transient": {
    "cluster.routing.allocation.enable": "all"
  }
}
```

### 5.4 滚动重启

```
场景：
- 升级ES版本
- 修改配置
- 维护节点

步骤：
1. 禁用分片分配
2. 停止一个节点
3. 执行维护操作
4. 启动节点
5. 等待节点加入集群
6. 启用分片分配
7. 等待集群恢复Green
8. 重复步骤1-7，直到所有节点完成
```

**详细步骤**：
```bash
# 步骤1：禁用分片分配
PUT /_cluster/settings
{
  "transient": {
    "cluster.routing.allocation.enable": "primaries"
  }
}

# 步骤2：停止节点
systemctl stop elasticsearch

# 步骤3：执行维护操作（升级、修改配置等）

# 步骤4：启动节点
systemctl start elasticsearch

# 步骤5：等待节点加入集群
GET /_cat/nodes?v

# 步骤6：启用分片分配
PUT /_cluster/settings
{
  "transient": {
    "cluster.routing.allocation.enable": "all"
  }
}

# 步骤7：等待集群恢复Green
GET /_cluster/health?wait_for_status=green&timeout=5m

# 重复以上步骤，处理下一个节点
```

---

## 本章总结

### 核心要点

1. **节点类型**
   - Master Node：集群管理
   - Data Node：数据存储和查询
   - Coordinating Node：请求路由和结果聚合
   - Ingest Node：数据预处理

2. **Master选举**
   - 基于Quorum机制
   - 需要过半数投票
   - ES 7.x+自动管理

3. **脑裂预防**
   - 使用Quorum机制
   - 奇数个Master候选节点（3或5个）
   - ES 7.x+自动计算

4. **集群监控**
   - 集群健康状态：Green/Yellow/Red
   - 节点状态：CPU、内存、磁盘
   - 分片状态：分配情况、未分配原因

5. **扩容缩容**
   - 扩容：添加节点，自动重新平衡
   - 缩容：排空节点，迁移分片
   - 滚动重启：不停机维护

### 最佳实践

```
✅ 集群规划：
1. 至少3个节点
2. 3或5个Master候选节点
3. 专用Master节点（生产环境）
4. 数据节点分层（Hot/Warm/Cold）

✅ 高可用配置：
1. 至少1个副本
2. 分片均匀分布
3. 配置机架感知
4. 定期备份

✅ 监控告警：
1. 监控集群健康状态
2. 监控JVM堆内存
3. 监控磁盘空间
4. 监控GC频率

✅ 运维操作：
1. 使用滚动重启
2. 扩容前评估容量
3. 缩容前排空节点
4. 定期检查集群状态
```

### 常见问题

```
Q1：集群最少需要几个节点？
A1：最少3个节点（保证高可用）

Q2：为什么推荐3或5个Master候选节点？
A2：奇数节点可以避免脑裂，3个容忍1个故障，5个容忍2个故障

Q3：如何判断集群是否健康？
A3：查看cluster health，Green表示健康

Q4：Yellow状态是否需要处理？
A4：取决于原因，如果是副本未分配，可以增加节点或减少副本数

Q5：如何安全地移除节点？
A5：先排空节点，等待分片迁移完成，再停止节点
```

---

## 下一章预告

**08-Elasticsearch安装与配置**

下一章将详细讲解：
- ES的安装方式（单机、集群）
- 重要配置参数详解
- JVM参数调优
- 安全配置（X-Pack）
- Docker部署
- Kubernetes部署

敬请期待！
