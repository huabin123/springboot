# 12-性能优化与踩坑指南

## 本章概述

本章详细讲解Elasticsearch的性能优化技巧和常见问题，重点解决以下问题：
- **问题1**：写入性能如何优化？
- **问题2**：查询性能如何优化？
- **问题3**：有哪些常见的坑？如何避免？
- **问题4**：如何监控ES性能？
- **问题5**：生产环境最佳实践有哪些？

---

## 问题1：写入性能如何优化？

### 1.1 批量写入

```java
// ❌ 不推荐：单条写入
for (int i = 0; i < 10000; i++) {
    IndexRequest request = new IndexRequest("products")
        .id(String.valueOf(i))
        .source("name", "Product " + i, "price", 100);
    client.index(request, RequestOptions.DEFAULT);
}
// 性能：慢，10000次网络请求

// ✅ 推荐：批量写入
BulkRequest bulkRequest = new BulkRequest();
for (int i = 0; i < 10000; i++) {
    bulkRequest.add(new IndexRequest("products")
        .id(String.valueOf(i))
        .source("name", "Product " + i, "price", 100));
    
    // 每1000条提交一次
    if (i % 1000 == 0) {
        client.bulk(bulkRequest, RequestOptions.DEFAULT);
        bulkRequest = new BulkRequest();
    }
}
// 最后提交剩余的
if (bulkRequest.numberOfActions() > 0) {
    client.bulk(bulkRequest, RequestOptions.DEFAULT);
}

性能提升：10-50倍
```

### 1.2 调整Refresh间隔

```json
// 默认配置：每1秒refresh一次
PUT /products/_settings
{
  "index.refresh_interval": "1s"
}

// 批量导入时：禁用自动refresh
PUT /products/_settings
{
  "index.refresh_interval": "-1"
}

// 导入完成后：恢复refresh
PUT /products/_settings
{
  "index.refresh_interval": "1s"
}

// 手动触发refresh
POST /products/_refresh

性能提升：5-10倍

原因：
- refresh会将内存缓冲区的数据写入segment
- 频繁refresh会产生大量小segment
- 禁用refresh可以减少IO操作
```

### 1.3 增加Bulk线程池和队列大小

```yaml
# elasticsearch.yml

# 写入线程池
thread_pool.write.size: 30
thread_pool.write.queue_size: 1000

# 说明：
# - size：线程数，默认为CPU核数
# - queue_size：队列大小，默认200

# 监控线程池状态
GET /_cat/thread_pool/write?v&h=node_name,name,active,queue,rejected
```

### 1.4 调整Translog设置

```json
// 默认配置：每次请求后fsync
PUT /products/_settings
{
  "index.translog.durability": "request",
  "index.translog.sync_interval": "5s"
}

// 高性能配置：异步fsync（可能丢失5秒数据）
PUT /products/_settings
{
  "index.translog.durability": "async",
  "index.translog.sync_interval": "5s"
}

性能提升：2-3倍
风险：断电可能丢失最近5秒的数据

适用场景：
- 日志数据（可接受少量丢失）
- 批量导入（导入完成后可验证）
```

### 1.5 先导入数据，再增加副本

```json
// ✅ 推荐流程：

// 1. 创建索引时，设置0个副本
PUT /products
{
  "settings": {
    "number_of_shards": 5,
    "number_of_replicas": 0
  }
}

// 2. 批量导入数据

// 3. 导入完成后，增加副本
PUT /products/_settings
{
  "number_of_replicas": 1
}

性能提升：2倍

原因：
- 写入时不需要同步到副本
- 副本通过复制主分片创建，比逐条同步快
```

### 1.6 使用自动生成的ID

```java
// ❌ 不推荐：手动指定ID
IndexRequest request = new IndexRequest("products")
    .id("custom-id-123")  // 需要先查询ID是否存在
    .source("name", "Product");

// ✅ 推荐：自动生成ID
IndexRequest request = new IndexRequest("products")
    .source("name", "Product");  // ES自动生成ID，跳过查询

性能提升：10-20%

原因：
- 自动生成ID跳过了ID存在性检查
- 减少了一次查询操作
```

### 1.7 使用routing优化

```java
// 使用routing将相关文档路由到同一分片
IndexRequest request = new IndexRequest("products")
    .routing("user-123")  // 同一用户的数据在同一分片
    .source("user_id", "user-123", "name", "Product");

优势：
- 查询时只需要查询一个分片
- 提升查询性能
```

### 1.8 禁用不需要的功能

```json
PUT /logs
{
  "mappings": {
    "properties": {
      "message": {
        "type": "text",
        "norms": false,        // 禁用评分归一化
        "index_options": "docs"  // 只索引文档，不索引词频和位置
      },
      "timestamp": {
        "type": "date",
        "doc_values": false    // 禁用doc_values（如果不需要聚合和排序）
      }
    }
  }
}

说明：
- norms：用于评分归一化，不需要评分时可禁用
- index_options：控制索引的详细程度
  - docs：只索引文档
  - freqs：索引文档和词频
  - positions：索引文档、词频和位置
  - offsets：索引文档、词频、位置和偏移量
- doc_values：用于聚合和排序，不需要时可禁用
```

---

## 问题2：查询性能如何优化？

### 2.1 使用Filter代替Query

```json
// ❌ 不推荐：使用must（计算评分）
GET /products/_search
{
  "query": {
    "bool": {
      "must": [
        { "term": { "category": "手机" } },
        { "range": { "price": { "gte": 1000, "lte": 5000 } } }
      ]
    }
  }
}

// ✅ 推荐：使用filter（不计算评分，可缓存）
GET /products/_search
{
  "query": {
    "bool": {
      "filter": [
        { "term": { "category": "手机" } },
        { "range": { "price": { "gte": 1000, "lte": 5000 } } }
      ]
    }
  }
}

性能提升：2-5倍

原因：
- filter不计算评分，速度更快
- filter结果可以缓存
- 适用于精确匹配、范围查询
```

### 2.2 避免深度分页

```json
// ❌ 不推荐：深度分页
GET /products/_search
{
  "from": 10000,
  "size": 10
}

问题：
- 每个分片需要返回Top 10010个文档
- 协调节点需要排序 10010 * 分片数 个文档
- 内存占用大，性能差

// ✅ 推荐：使用search_after
GET /products/_search
{
  "size": 10,
  "sort": [
    { "price": "asc" },
    { "_id": "asc" }
  ],
  "search_after": [999, "product-100"]
}

性能提升：10-100倍
```

### 2.3 只返回需要的字段

```json
// ❌ 不推荐：返回所有字段
GET /products/_search
{
  "query": { "match_all": {} }
}

// ✅ 推荐：只返回需要的字段
GET /products/_search
{
  "query": { "match_all": {} },
  "_source": ["name", "price", "category"]
}

// 或者排除大字段
GET /products/_search
{
  "query": { "match_all": {} },
  "_source": {
    "excludes": ["description", "images"]
  }
}

性能提升：2-3倍（减少网络传输）
```

### 2.4 使用routing优化查询

```json
// 不使用routing：查询所有分片
GET /products/_search
{
  "query": {
    "term": { "user_id": "user-123" }
  }
}

// 使用routing：只查询一个分片
GET /products/_search?routing=user-123
{
  "query": {
    "term": { "user_id": "user-123" }
  }
}

性能提升：N倍（N为分片数）
```

### 2.5 预加载Fielddata

```json
// 对于需要聚合的text字段，预加载fielddata
POST /products/_cache/clear?fielddata=true

GET /products/_search
{
  "size": 0,
  "aggs": {
    "top_names": {
      "terms": {
        "field": "name",
        "eager_global_ordinals": true
      }
    }
  }
}

说明：
- eager_global_ordinals：预加载全局序号
- 适用于高频聚合字段
- 首次查询慢，后续查询快
```

### 2.6 使用Profile API分析查询

```json
// 分析查询性能
GET /products/_search
{
  "profile": true,
  "query": {
    "bool": {
      "must": [
        { "match": { "name": "手机" } }
      ],
      "filter": [
        { "range": { "price": { "gte": 1000 } } }
      ]
    }
  }
}

响应：
{
  "profile": {
    "shards": [
      {
        "searches": [
          {
            "query": [
              {
                "type": "BooleanQuery",
                "description": "...",
                "time_in_nanos": 1234567,
                "breakdown": {
                  "match": 100000,
                  "next_doc": 50000,
                  ...
                }
              }
            ]
          }
        ]
      }
    ]
  }
}

分析要点：
- time_in_nanos：查询耗时
- breakdown：详细的时间分解
- 找出耗时最多的操作
```

### 2.7 避免使用通配符和正则查询

```json
// ❌ 不推荐：通配符查询（性能极差）
GET /products/_search
{
  "query": {
    "wildcard": {
      "name": "*手机*"
    }
  }
}

// ✅ 推荐：使用match查询
GET /products/_search
{
  "query": {
    "match": {
      "name": "手机"
    }
  }
}

// 如果必须使用通配符，至少不要以*开头
GET /products/_search
{
  "query": {
    "wildcard": {
      "name": "手机*"  // 相对好一些
    }
  }
}
```

### 2.8 使用索引预热

```json
// 预热索引（将索引加载到OS Cache）
POST /products/_cache/clear

POST /products/_forcemerge?max_num_segments=1

GET /products/_search
{
  "query": { "match_all": {} },
  "size": 0
}

说明：
- 清除缓存
- 合并segment
- 执行一次查询，预热缓存
```

---

## 问题3：有哪些常见的坑？

### 3.1 坑1：Mapping爆炸

**问题描述**：
```json
// 动态Mapping，字段数量不受控制
POST /logs/_doc
{
  "user_123_action": "login",
  "user_456_action": "logout",
  "user_789_action": "view"
  // ... 每个用户一个字段，字段数量爆炸
}

问题：
- Mapping占用大量内存
- 集群状态变大
- 性能下降
```

**解决方案**：
```json
// 1. 设置字段数量限制
PUT /logs/_settings
{
  "index.mapping.total_fields.limit": 1000
}

// 2. 使用嵌套结构
POST /logs/_doc
{
  "user_actions": [
    { "user_id": "123", "action": "login" },
    { "user_id": "456", "action": "logout" }
  ]
}

// 3. 设置dynamic=strict
PUT /logs
{
  "mappings": {
    "dynamic": "strict",
    "properties": {
      "timestamp": { "type": "date" },
      "message": { "type": "text" }
    }
  }
}
```

### 3.2 坑2：深度分页OOM

**问题描述**：
```json
// 查询第10000页
GET /products/_search
{
  "from": 100000,
  "size": 10
}

问题：
- 每个分片需要返回Top 100010个文档
- 协调节点需要排序大量文档
- 内存溢出
```

**解决方案**：
```json
// 1. 设置max_result_window限制
PUT /products/_settings
{
  "index.max_result_window": 10000
}

// 2. 使用search_after
GET /products/_search
{
  "size": 10,
  "sort": [{ "price": "asc" }, { "_id": "asc" }],
  "search_after": [999, "product-100"]
}

// 3. 使用Scroll API（已废弃，不推荐）
```

### 3.3 坑3：text字段聚合

**问题描述**：
```json
// 对text字段聚合
GET /products/_search
{
  "size": 0,
  "aggs": {
    "top_names": {
      "terms": {
        "field": "name"  // name是text类型
      }
    }
  }
}

错误：
Fielddata is disabled on text fields by default.

原因：
- text字段默认禁用fielddata
- 启用fielddata会占用大量堆内存
```

**解决方案**：
```json
// 1. 使用keyword子字段（推荐）
GET /products/_search
{
  "size": 0,
  "aggs": {
    "top_names": {
      "terms": {
        "field": "name.keyword"
      }
    }
  }
}

// 2. 启用fielddata（不推荐）
PUT /products/_mapping
{
  "properties": {
    "name": {
      "type": "text",
      "fielddata": true
    }
  }
}
```

### 3.4 坑4：主分片数设置不当

**问题描述**：
```json
// 分片过多
PUT /products
{
  "settings": {
    "number_of_shards": 100  // 数据量只有10GB
  }
}

问题：
- 每个分片只有100MB数据
- 分片过多，资源浪费
- 查询需要合并100个分片的结果

// 分片过少
PUT /products
{
  "settings": {
    "number_of_shards": 1  // 数据量有1TB
  }
}

问题：
- 单分片1TB，过大
- 无法并行处理
- 恢复时间长
```

**解决方案**：
```json
// 合理设置分片数
PUT /products
{
  "settings": {
    "number_of_shards": 20,  // 1TB / 50GB = 20
    "number_of_replicas": 1
  }
}

建议：
- 单分片大小：20-50GB
- 单分片文档数：< 20亿
- 单节点分片数：< 1000
```

### 3.5 坑5：副本数设置不当

**问题描述**：
```json
// 副本数 > 节点数
PUT /products
{
  "settings": {
    "number_of_shards": 5,
    "number_of_replicas": 3  // 只有3个节点
  }
}

问题：
- 部分副本无法分配
- 集群状态Yellow
- 浪费资源
```

**解决方案**：
```json
// 副本数 < 节点数
PUT /products
{
  "settings": {
    "number_of_shards": 5,
    "number_of_replicas": 2  // 3个节点，2个副本
  }
}

建议：
- 副本数 = 节点数 - 1
- 或根据可用性需求设置
```

### 3.6 坑6：JVM堆内存设置不当

**问题描述**：
```bash
# 堆内存过大
-Xms64g
-Xmx64g

问题：
- 超过32GB，压缩指针失效
- 实际可用内存反而减少
- GC时间长

# 堆内存过小
-Xms2g
-Xmx2g

问题：
- 频繁GC
- OOM
```

**解决方案**：
```bash
# 推荐配置
-Xms16g
-Xmx16g

建议：
- 不超过物理内存的50%
- 不超过32GB
- Xms和Xmx设置相同
```

### 3.7 坑7：忘记关闭客户端

**问题描述**：
```java
// ❌ 不推荐：忘记关闭客户端
public void search() {
    RestHighLevelClient client = new RestHighLevelClient(
        RestClient.builder(new HttpHost("localhost", 9200))
    );
    
    // 执行查询
    SearchResponse response = client.search(request, RequestOptions.DEFAULT);
    
    // 忘记关闭客户端
}

问题：
- 连接泄漏
- 资源耗尽
```

**解决方案**：
```java
// ✅ 推荐：使用try-with-resources
public void search() {
    try (RestHighLevelClient client = new RestHighLevelClient(
        RestClient.builder(new HttpHost("localhost", 9200))
    )) {
        SearchResponse response = client.search(request, RequestOptions.DEFAULT);
    } catch (IOException e) {
        e.printStackTrace();
    }
}

// 或者使用单例模式
@Bean
public RestHighLevelClient elasticsearchClient() {
    return new RestHighLevelClient(
        RestClient.builder(new HttpHost("localhost", 9200))
    );
}

@PreDestroy
public void destroy() throws IOException {
    elasticsearchClient().close();
}
```

### 3.8 坑8：使用Script查询

**问题描述**：
```json
// ❌ 不推荐：使用Script查询
GET /products/_search
{
  "query": {
    "script": {
      "script": {
        "source": "doc['price'].value * doc['discount'].value < 1000"
      }
    }
  }
}

问题：
- 性能极差
- 每个文档都需要执行脚本
- 无法使用索引
```

**解决方案**：
```json
// ✅ 推荐：在索引时计算
PUT /products/_doc/1
{
  "price": 1200,
  "discount": 0.8,
  "final_price": 960  // 索引时计算
}

GET /products/_search
{
  "query": {
    "range": {
      "final_price": {
        "lt": 1000
      }
    }
  }
}
```

---

## 问题4：如何监控ES性能？

### 4.1 集群健康监控

```bash
# 查看集群健康状态
GET /_cluster/health

# 响应
{
  "cluster_name": "my-cluster",
  "status": "green",  // green/yellow/red
  "timed_out": false,
  "number_of_nodes": 3,
  "number_of_data_nodes": 3,
  "active_primary_shards": 10,
  "active_shards": 20,
  "relocating_shards": 0,
  "initializing_shards": 0,
  "unassigned_shards": 0
}

关键指标：
- status：集群状态
- unassigned_shards：未分配的分片数
- relocating_shards：正在迁移的分片数
```

### 4.2 节点性能监控

```bash
# 查看节点统计
GET /_nodes/stats

# 关键指标
{
  "nodes": {
    "node-1": {
      "jvm": {
        "mem": {
          "heap_used_percent": 75,  // 堆内存使用率
          "heap_used_in_bytes": 8589934592
        },
        "gc": {
          "collectors": {
            "young": {
              "collection_count": 100,
              "collection_time_in_millis": 1000
            },
            "old": {
              "collection_count": 5,
              "collection_time_in_millis": 500
            }
          }
        }
      },
      "process": {
        "cpu": {
          "percent": 50  // CPU使用率
        }
      },
      "fs": {
        "total": {
          "available_in_bytes": 549755813888  // 可用磁盘空间
        }
      }
    }
  }
}

告警阈值：
- heap_used_percent > 85%：内存告警
- old GC频率过高：GC告警
- CPU > 80%：CPU告警
- 可用磁盘 < 15%：磁盘告警
```

### 4.3 索引性能监控

```bash
# 查看索引统计
GET /products/_stats

# 关键指标
{
  "indices": {
    "products": {
      "primaries": {
        "docs": {
          "count": 1000000  // 文档数
        },
        "store": {
          "size_in_bytes": 10737418240  // 存储大小
        },
        "indexing": {
          "index_total": 1000000,
          "index_time_in_millis": 60000,  // 索引耗时
          "index_current": 0
        },
        "search": {
          "query_total": 10000,
          "query_time_in_millis": 5000,  // 查询耗时
          "query_current": 2
        }
      }
    }
  }
}

计算指标：
- 平均索引时间 = index_time_in_millis / index_total
- 平均查询时间 = query_time_in_millis / query_total
```

### 4.4 慢查询监控

```yaml
# elasticsearch.yml

# 慢查询日志配置
index.search.slowlog.threshold.query.warn: 10s
index.search.slowlog.threshold.query.info: 5s
index.search.slowlog.threshold.query.debug: 2s
index.search.slowlog.threshold.query.trace: 500ms

index.indexing.slowlog.threshold.index.warn: 10s
index.indexing.slowlog.threshold.index.info: 5s
index.indexing.slowlog.threshold.index.debug: 2s
index.indexing.slowlog.threshold.index.trace: 500ms
```

```bash
# 查看慢查询日志
tail -f /var/log/elasticsearch/my-cluster_index_search_slowlog.log

# 日志示例
[2024-01-20T10:00:00,000][WARN ][index.search.slowlog.query] [node-1] [products][0] took[5.2s], took_millis[5200], types[], stats[], search_type[QUERY_THEN_FETCH], total_shards[5], source[{"query":{"match":{"name":"手机"}}}]
```

### 4.5 使用Kibana监控

```
Kibana Monitoring功能：
1. 集群概览
   - 集群健康状态
   - 节点数量
   - 索引数量
   - 文档数量

2. 节点监控
   - CPU使用率
   - 内存使用率
   - 磁盘使用率
   - JVM堆内存

3. 索引监控
   - 索引速率
   - 查询速率
   - 索引大小
   - 文档数量

4. 性能指标
   - 查询延迟
   - 索引延迟
   - GC频率
   - 线程池状态
```

### 4.6 使用Prometheus + Grafana

```yaml
# prometheus.yml
scrape_configs:
  - job_name: 'elasticsearch'
    static_configs:
      - targets: ['localhost:9200']
    metrics_path: '/_prometheus/metrics'
```

```bash
# 安装elasticsearch_exporter
docker run -d \
  --name elasticsearch-exporter \
  -p 9114:9114 \
  quay.io/prometheuscommunity/elasticsearch-exporter:latest \
  --es.uri=http://localhost:9200
```

**关键监控指标**：
```
# 集群健康
elasticsearch_cluster_health_status

# JVM堆内存
elasticsearch_jvm_memory_used_bytes
elasticsearch_jvm_memory_max_bytes

# GC
elasticsearch_jvm_gc_collection_seconds_count
elasticsearch_jvm_gc_collection_seconds_sum

# 索引性能
elasticsearch_indices_indexing_index_total
elasticsearch_indices_indexing_index_time_seconds_total

# 查询性能
elasticsearch_indices_search_query_total
elasticsearch_indices_search_query_time_seconds_total

# 磁盘
elasticsearch_filesystem_data_available_bytes
elasticsearch_filesystem_data_size_bytes
```

---

## 问题5：生产环境最佳实践

### 5.1 硬件配置

```
推荐配置：

1. CPU
   - 数据节点：16核以上
   - Master节点：4核
   - Coordinating节点：8核

2. 内存
   - 数据节点：64GB以上
   - Master节点：8GB
   - Coordinating节点：16GB
   - JVM堆内存：不超过32GB

3. 磁盘
   - 类型：SSD（强烈推荐）
   - 容量：根据数据量计算
   - RAID：RAID 0（ES自带副本机制）

4. 网络
   - 带宽：万兆网卡
   - 延迟：低延迟网络
```

### 5.2 集群规划

```
小型集群（< 10节点）：
- 3个全能节点（Master + Data + Coordinating）
- 适用场景：开发、测试、小型生产环境

中型集群（10-50节点）：
- 3个专用Master节点（4核8GB）
- N个Data节点（16核64GB）
- 2个Coordinating节点（8核16GB）
- 适用场景：中型生产环境

大型集群（> 50节点）：
- 5个专用Master节点（4核8GB）
- N个Data节点（分层：Hot/Warm/Cold）
  - Hot：SSD，16核64GB
  - Warm：SSD，8核32GB
  - Cold：HDD，4核16GB
- 3-5个Coordinating节点（16核32GB）
- 2个Ingest节点（8核16GB）
- 适用场景：大型生产环境
```

### 5.3 索引设计

```json
// 1. 合理设置分片数
PUT /products
{
  "settings": {
    "number_of_shards": 10,  // 预估数据量 / 50GB
    "number_of_replicas": 1
  }
}

// 2. 使用索引模板
PUT /_index_template/logs_template
{
  "index_patterns": ["logs-*"],
  "template": {
    "settings": {
      "number_of_shards": 3,
      "number_of_replicas": 1,
      "index.lifecycle.name": "logs_policy"
    }
  }
}

// 3. 使用ILM管理生命周期
PUT /_ilm/policy/logs_policy
{
  "policy": {
    "phases": {
      "hot": {
        "actions": {
          "rollover": {
            "max_size": "50GB",
            "max_age": "1d"
          }
        }
      },
      "warm": {
        "min_age": "7d",
        "actions": {
          "forcemerge": {
            "max_num_segments": 1
          }
        }
      },
      "delete": {
        "min_age": "90d",
        "actions": {
          "delete": {}
        }
      }
    }
  }
}
```

### 5.4 备份策略

```json
// 1. 配置快照仓库
PUT /_snapshot/my_backup
{
  "type": "fs",
  "settings": {
    "location": "/backup/elasticsearch"
  }
}

// 2. 创建快照
PUT /_snapshot/my_backup/snapshot_1
{
  "indices": "products,orders",
  "ignore_unavailable": true,
  "include_global_state": false
}

// 3. 定期备份（使用cron）
# 每天凌晨2点备份
0 2 * * * curl -X PUT "localhost:9200/_snapshot/my_backup/snapshot_$(date +\%Y\%m\%d)"

// 4. 恢复快照
POST /_snapshot/my_backup/snapshot_1/_restore
{
  "indices": "products",
  "ignore_unavailable": true
}
```

### 5.5 安全配置

```yaml
# elasticsearch.yml

# 1. 启用安全功能
xpack.security.enabled: true

# 2. 启用SSL/TLS
xpack.security.transport.ssl.enabled: true
xpack.security.http.ssl.enabled: true

# 3. 配置审计日志
xpack.security.audit.enabled: true

# 4. 限制网络访问
network.host: 192.168.1.101
http.host: 192.168.1.101
```

### 5.6 监控告警

```
关键监控指标：

1. 集群健康
   - 告警：status != green
   - 级别：Critical

2. JVM堆内存
   - 告警：heap_used_percent > 85%
   - 级别：Warning（85%）, Critical（95%）

3. 磁盘空间
   - 告警：available < 15%
   - 级别：Warning（15%）, Critical（5%）

4. GC频率
   - 告警：old GC time > 1s
   - 级别：Warning（1s）, Critical（5s）

5. 查询延迟
   - 告警：avg_query_time > 1s
   - 级别：Warning（1s）, Critical（5s）

6. 节点可用性
   - 告警：节点数减少
   - 级别：Critical
```

### 5.7 容量规划

```
计算公式：

1. 存储容量
   原始数据大小 * (1 + 副本数) * 1.5（索引开销）

   示例：
   - 原始数据：1TB
   - 副本数：1
   - 存储容量：1TB * (1 + 1) * 1.5 = 3TB

2. 节点数量
   总存储容量 / 单节点容量

   示例：
   - 总存储容量：3TB
   - 单节点容量：500GB
   - 节点数量：3TB / 500GB = 6个节点

3. 分片数量
   总数据量 / 单分片最大容量（50GB）

   示例：
   - 总数据量：1TB
   - 单分片：50GB
   - 分片数量：1TB / 50GB = 20个主分片
```

---

## 本章总结

### 核心要点

1. **写入优化**
   - 批量写入
   - 调整refresh间隔
   - 先导入数据，再增加副本
   - 使用自动生成的ID

2. **查询优化**
   - 使用filter代替query
   - 避免深度分页
   - 只返回需要的字段
   - 使用routing优化

3. **常见的坑**
   - Mapping爆炸
   - 深度分页OOM
   - text字段聚合
   - 分片数设置不当

4. **性能监控**
   - 集群健康监控
   - 节点性能监控
   - 慢查询监控
   - 使用Prometheus + Grafana

5. **生产最佳实践**
   - 合理的硬件配置
   - 专用节点分离
   - 索引生命周期管理
   - 定期备份

### 最佳实践清单

```
✅ 写入优化：
1. 使用批量写入（每批1000-5000条）
2. 批量导入时禁用refresh
3. 先导入数据，再增加副本
4. 使用自动生成的ID

✅ 查询优化：
1. 精确匹配使用filter
2. 使用search_after代替深度分页
3. 只返回需要的字段
4. 避免通配符和正则查询

✅ 配置优化：
1. JVM堆内存不超过32GB
2. 单分片大小20-50GB
3. 副本数 = 节点数 - 1
4. 开启慢查询日志

✅ 监控告警：
1. 监控集群健康状态
2. 监控JVM堆内存（> 85%告警）
3. 监控磁盘空间（< 15%告警）
4. 监控GC频率

✅ 运维实践：
1. 定期备份（每天）
2. 使用ILM管理生命周期
3. 启用安全认证
4. 制定容量规划
```

---

## 下一章预告

**13-Elasticsearch优缺点分析**

下一章将详细讲解：
- Elasticsearch的优点
- Elasticsearch的缺点
- 适用场景分析
- 不适用场景分析
- 使用决策树

敬请期待！
