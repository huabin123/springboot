# hashtable 哈希表详解

> **核心问题**：为什么 hashtable 能实现 O(1) 查询？代价是什么？

## 一、为什么需要 hashtable？

### 问题 1：ziplist 在什么场景下会成为瓶颈？

**场景：电商购物车**

```
用户购物车有 500 个商品：
HSET cart:12345 product1 "1" product2 "2" ... product500 "500"

查询最后一个商品：
HGET cart:12345 product500

ziplist 查询过程：
┌────┬────┬────┬────┬────┬────┬────┬────┬────┬────┐
│ p1 │ 1  │ p2 │ 2  │ p3 │ 3  │... │p500│500 │    │
└────┴────┴────┴────┴────┴────┴────┴────┴────┴────┘
  ↑                                      ↑
  从头开始 ──────────────────────────────→ 找到！

需要遍历 500 次，耗时：2.5ms

问题：
- ❌ 用户添加商品：HSET 需要移动内存，耗时 4ms
- ❌ 用户删除商品：HDEL 需要移动内存，耗时 5ms
- ❌ 高峰期 1000 QPS，Redis CPU 100%
- ❌ 大量请求超时，用户投诉
```

**核心矛盾**：大对象 + 频繁更新 = 性能灾难

### 问题 2：hashtable 如何解决这个问题？

**答案：O(1) 查询 + O(1) 更新**

```
hashtable 查询过程：
1. 计算 hash("product500") = 0x1234ABCD
2. 定位桶：index = 0x1234ABCD & 511 = 205
3. 在桶中查找（通常只有 1-2 个节点）
4. 找到返回

哈希表数组（size=512）
┌───┬───┬───┬─────┬───┬───┬───┐
│ 0 │ 1 │ 2 │ 205 │...│510│511│
└───┴───┴───┴──┬──┴───┴───┴───┘
               │
               ↓
          ┌─────────┐
          │product500│
          └─────────┘

耗时：0.01ms（250 倍提升！）

优势：
- ✅ 查询：O(1)，0.01ms
- ✅ 插入：O(1)，0.02ms
- ✅ 删除：O(1)，0.02ms
- ✅ 与字段数无关
```

---

## 二、hashtable 的精妙设计

### 问题 3：如何实现 O(1) 查询？

**核心技术：哈希函数 + 数组索引**

```
步骤 1：计算哈希值
key = "product500"
hash = siphash(key) = 0x1234ABCD5678EF90

步骤 2：计算数组索引
size = 512（哈希表大小，2^9）
sizemask = 511（size - 1 = 0b111111111）
index = hash & sizemask = 0x1234ABCD5678EF90 & 0b111111111 = 205

步骤 3：访问数组
table[205] → dictEntry → 找到 "product500"

时间复杂度：O(1)
```

**为什么 size 必须是 2^n？**

```
如果 size = 2^n，则 sizemask = 2^n - 1

例如：size = 512 = 2^9
sizemask = 511 = 0b111111111（9 个 1）

hash & sizemask 相当于 hash % size
但位运算比取模快得多！

性能对比：
- hash & sizemask：1 个 CPU 周期
- hash % size：10-20 个 CPU 周期
```

**为什么 hash & sizemask 相当于 hash % size？**

```
数学原理：当 size = 2^n 时，hash % size 等价于取 hash 的低 n 位

证明：
假设 size = 8 = 2^3
sizemask = 7 = 0b111

任意数字 hash 可以表示为：
hash = q × 8 + r（其中 0 ≤ r < 8）

则：
hash % 8 = r（取模运算，余数就是 r）

hash & 0b111 = ?
- hash 的二进制表示：...xxxyyy（yyy 是低 3 位）
- 0b111 的二进制表示：00000111
- 按位与运算：只保留低 3 位，即 yyy

而 yyy 正好就是 r（因为 r < 8，只需要 3 位表示）

结论：hash & sizemask = hash % size
```

**实际示例：**

```
例 1：hash = 205, size = 8
方法 1（取模）：
205 % 8 = 5

方法 2（位运算）：
205 = 0b11001101
  7 = 0b00000111
205 & 7 = 0b00000101 = 5

结果相同！✅

例 2：hash = 0x1234ABCD, size = 512
方法 1（取模）：
0x1234ABCD % 512 = 205

方法 2（位运算）：
0x1234ABCD = 0b...11001101（低 9 位）
      511 = 0b111111111
0x1234ABCD & 511 = 0b011001101 = 205

结果相同！✅
```

**为什么位运算更快？**

```
CPU 指令对比：

取模运算（hash % size）：
1. 除法指令（DIV）：10-20 个时钟周期
2. 取余数
3. 返回结果

位运算（hash & sizemask）：
1. 按位与指令（AND）：1 个时钟周期
2. 返回结果

性能差异：10-20 倍！

这就是为什么 Redis 要求 size 必须是 2^n
```

### 问题 4：如何解决哈希冲突？

**方法：链表法（Chaining）**

```
场景：两个 key 哈希到同一个桶

hash("name") & 511 = 100
hash("city") & 511 = 100  ← 冲突！

解决方案：用链表连接
┌─────┬─────┬─────┬─────┐
│  0  │  1  │ 100 │ 101 │
└─────┴─────┴──┬──┴─────┘
               │
               ↓
          ┌────────┐
          │  name  │
          │ "Alice"│
          └────┬───┘
               │ next
               ↓
          ┌────────┐
          │  city  │
          │"Beijing"│
          └────────┘

查询过程：
1. 定位桶：table[100]
2. 遍历链表：name → city
3. 找到返回

时间复杂度：O(k)，k 为链表长度（通常 k ≤ 2）
```

**为什么链表长度通常 ≤ 2？**

```
负载因子 = used / size

Redis 的策略：
- 负载因子 >= 1 时触发 rehash
- 扩容到 2 倍大小

例如：
size = 512, used = 512
负载因子 = 512 / 512 = 1
→ 触发 rehash，扩容到 1024

扩容后：
size = 1024, used = 512
负载因子 = 512 / 1024 = 0.5
→ 每个桶平均 0.5 个节点
→ 链表长度通常 ≤ 2
```

### 问题 5：什么是渐进式 rehash？

**挑战：一次性 rehash 会阻塞服务**

```
场景：100 万个 key 需要 rehash

一次性 rehash：
1. 分配新哈希表（size = 2M）
2. 遍历旧哈希表（1M 个节点）
3. 重新计算哈希值并插入新表
4. 释放旧哈希表

耗时：100-200ms
影响：所有请求阻塞，用户超时
```

**解决方案：渐进式 rehash**

```
核心思想：分散到多次操作中，每次只迁移少量数据

初始状态：
ht[0]: size=512, used=512  ← 旧表
ht[1]: size=1024, used=0   ← 新表（已分配）
rehashidx = 0              ← 从索引 0 开始

每次操作（HSET/HGET/HDEL）时：
1. 执行正常操作
2. 顺便迁移 ht[0][rehashidx] 的所有节点到 ht[1]
3. rehashidx++

┌─────┬─────┬─────┬─────┐
│  0  │  1  │  2  │ ... │  ht[0]
└──┬──┴──┬──┴──┬──┴─────┘
   │     │     │
   ↓     ↓     ↓
  已迁移 已迁移 待迁移

┌─────┬─────┬─────┬─────┬─────┬─────┐
│  0  │  1  │  2  │  3  │ ... │1023 │  ht[1]
└──┬──┴──┬──┴─────┴─────┴─────┴─────┘
   │     │
   ↓     ↓
 已迁移的节点

rehashidx = 2

优势：
- ✅ 每次操作只增加 < 1ms
- ✅ 用户无感知
- ✅ 不阻塞服务
```

**rehash 期间的操作如何处理？**

```
查询（HGET）：
1. 先查 ht[0]
2. 如果没找到，再查 ht[1]

写入（HSET）：
1. 直接写入 ht[1]（新表）
2. 不再写入 ht[0]（旧表）

删除（HDEL）：
1. 先查 ht[0]，找到则删除
2. 如果没找到，再查 ht[1]，找到则删除

完成标志：
rehashidx = -1  ← 表示 rehash 完成
ht[0] = ht[1]
ht[1] = NULL
```

---

## 三、内存开销分析

### 问题 6：hashtable 的内存开销有多大？

**完整示例：存储 3 个字段**

```
HSET user:1 name "Alice" age "25" city "Beijing"

内存布局：
┌─────────────────────────────────────────────────────────────┐
│                  redisObject (16B)                           │
├─────────────────────────────────────────────────────────────┤
│                     dict (124B)                              │
│  - dictType*: 8B                                             │
│  - privdata*: 8B                                             │
│  - ht[0]: 32B, ht[1]: 32B                                    │
│  - rehashidx: 8B                                             │
│  - iterators: 4B                                             │
├─────────────────────────────────────────────────────────────┤
│                  哈希表数组 (32B)                             │
│  - size=4, 每个指针 8B                                        │
├─────────────────────────────────────────────────────────────┤
│                 dictEntry #1 (24B)                           │
│  - key* → SDS("name", 9B)                                    │
│  - val* → SDS("Alice", 10B)                                  │
│  - next*: NULL                                               │
├─────────────────────────────────────────────────────────────┤
│                 dictEntry #2 (24B)                           │
│  - key* → SDS("age", 8B)                                     │
│  - val* → SDS("25", 8B)                                      │
│  - next*: NULL                                               │
├─────────────────────────────────────────────────────────────┤
│                 dictEntry #3 (24B)                           │
│  - key* → SDS("city", 9B)                                    │
│  - val* → SDS("Beijing", 12B)                                │
│  - next*: NULL                                               │
└─────────────────────────────────────────────────────────────┘

总计：
- 固定开销：16 + 124 + 32 = 172B
- dictEntry：24 × 3 = 72B
- key SDS：9 + 8 + 9 = 26B
- value SDS：10 + 8 + 12 = 30B
- 总计：172 + 72 + 26 + 30 = 300B

对比 ziplist：47B
差异：300 / 47 = 6.4 倍
```

**内存开销来源分析：**

| 组件 | 大小 | 占比 | 说明 |
|------|------|------|------|
| 固定开销 | 172B | 57% | redisObject + dict + 数组 |
| dictEntry | 72B | 24% | 3 个指针 × 3 个节点 |
| SDS 头部 | 15B | 5% | 5B × 3 个 key |
| 实际数据 | 41B | 14% | key + value 内容 |

**结论**：固定开销占 57%，这就是为什么 hashtable 不适合小对象！

### 问题 7：为什么 hashtable 适合大对象？

**对比分析：不同字段数的内存效率**

| 字段数 | ziplist | hashtable | hashtable 开销 | 开销占比 |
|-------|---------|-----------|---------------|---------|
| 3 | 47B | 300B | 253B | 84% |
| 10 | 128B | 612B | 484B | 79% |
| 50 | 480B | 2856B | 2376B | 83% |
| 100 | 980B | 5612B | 4632B | 83% |
| 500 | - | 27KB | 22KB | 81% |

**关键发现：**

```
固定开销（172B）在不同字段数下的占比：

3 个字段：172 / 300 = 57%  ← 浪费严重
10 个字段：172 / 612 = 28%  ← 还可以接受
50 个字段：172 / 2856 = 6%  ← 可以接受
100 个字段：172 / 5612 = 3%  ← 很划算

结论：字段数越多，固定开销占比越小，hashtable 越划算
```

---

## 四、性能分析

### 问题 8：hashtable 的性能优势有多大？

**查询性能对比：**

| 字段数 | ziplist | hashtable | 提升倍数 |
|-------|---------|-----------|---------|
| 10 | 0.05ms | 0.01ms | **5倍** |
| 50 | 0.25ms | 0.01ms | **25倍** |
| 100 | 0.50ms | 0.01ms | **50倍** |
| 500 | 2.50ms | 0.01ms | **250倍** |
| 1000 | 5.00ms | 0.01ms | **500倍** |

**更新性能对比：**

| 操作 | ziplist | hashtable | 提升倍数 |
|------|---------|-----------|---------|
| HSET（头部） | 0.10ms | 0.02ms | **5倍** |
| HSET（尾部） | 0.05ms | 0.02ms | **2.5倍** |
| HDEL（头部） | 0.15ms | 0.02ms | **7.5倍** |
| HDEL（中间） | 0.20ms | 0.02ms | **10倍** |

**结论**：字段数越多，hashtable 性能优势越明显！

### 问题 9：何时使用 hashtable？

**决策树：**

```
字段数 > 512？
  ↓ 是
【自动转换为 hashtable】

  ↓ 否
值大小 > 64字节？
  ↓ 是
【自动转换为 hashtable】

  ↓ 否
QPS > 10000？
  ↓ 是
【建议使用 hashtable】

  ↓ 否
频繁更新？
  ↓ 是
【建议使用 hashtable】

  ↓ 否
【使用 ziplist 更好】
```

**适用场景：**

| 场景 | 是否适合 | 原因 |
|------|---------|------|
| 购物车 | ✅ 非常适合 | 字段动态增长、频繁更新 |
| 会话数据 | ✅ 非常适合 | 字段多、需要快速查询 |
| 用户画像 | ✅ 适合 | 字段多（标签） |
| 配置中心 | ✅ 适合 | 值可能很大 |
| 用户基本信息 | ❌ 不适合 | 字段少、值小，用 ziplist 更好 |
| 商品属性 | ❌ 不适合 | 字段少、值小，用 ziplist 更好 |

---

## 五、ziplist vs hashtable 全方位对比

### 对比矩阵

| 维度 | ziplist | hashtable | 胜者 |
|------|---------|-----------|------|
| **内存占用** | 47B（3字段） | 300B（3字段） | ziplist（6.4倍） |
| **查询性能** | O(N)，0.5ms（100字段） | O(1)，0.01ms | hashtable（50倍） |
| **更新性能** | O(N)，需要移动内存 | O(1)，只改指针 | hashtable（5-10倍） |
| **适用字段数** | < 100 | > 100 | - |
| **适用值大小** | < 64B | 任意 | - |
| **适用 QPS** | < 5000 | 任意 | - |
| **适用场景** | 小对象、读多写少 | 大对象、频繁更新 | - |

### 转换条件

```
ziplist → hashtable 自动转换条件：
1. 字段数 > hash-max-ziplist-entries（默认 512）
2. 单个值 > hash-max-ziplist-value（默认 64 字节）

转换是单向的，不可逆！
```

### 实际案例

**案例 1：用户基本信息（适合 ziplist）**

```
数据特征：
- 字段数：5-10（name, age, city, phone, email）
- 值大小：< 50 字节
- QPS：< 1000
- 读写比：90% 读，10% 写

选择：ziplist
理由：
- 内存节省 80%
- 查询性能可接受（0.05ms）
- 读多写少，更新性能影响小
```

**案例 2：购物车（适合 hashtable）**

```
数据特征：
- 字段数：10-500（商品数量动态变化）
- 值大小：< 20 字节
- QPS：> 10000
- 读写比：50% 读，50% 写

选择：hashtable
理由：
- 字段数多，ziplist 查询慢
- 频繁更新，ziplist 需要移动内存
- 高 QPS，需要 O(1) 性能
```

---

## 六、总结与最佳实践

### 核心要点

```
hashtable 的优势：
✅ O(1) 查询，与字段数无关
✅ O(1) 更新，只改指针
✅ 适合大对象、频繁更新
✅ 渐进式 rehash，不阻塞服务

hashtable 的代价：
❌ 内存开销大（6-7 倍）
❌ 固定开销高（172B）
❌ 不适合小对象
❌ 有内存碎片问题
```

### 最佳实践

```
1. 合理设置初始大小
   - 预估字段数，避免频繁 rehash
   - 使用 HMSET 批量写入

2. 控制字段数量
   - 单个 Hash < 10000 个字段
   - 超过 10000 考虑拆分

3. 监控内存使用
   - 定期检查 INFO memory
   - 监控 mem_fragmentation_ratio

4. 避免大 key
   - 单个 Hash > 10MB 考虑拆分
   - 使用 SCAN 而非 HGETALL
```

### 关键数据

```
内存开销：6-7 倍（vs ziplist）
查询性能：O(1)，0.01ms
更新性能：O(1)，0.02ms
固定开销：172B
适用场景：大对象、频繁更新、高 QPS
```
