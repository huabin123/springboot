# 内存优化实战案例

> **真实场景**：电商系统 Redis 内存从 10GB 降到 3GB，节省 70% 内存，无需扩容硬件

## 一、问题背景

### 1.1 业务场景

某电商系统使用 Redis 存储用户信息和商品信息：

```
用户信息：100 万用户
- user:{userId} → Hash
- 字段：id, name, email, phone, city, age, vip_level, created_at

商品信息：50 万商品
- product:{productId} → Hash
- 字段：id, name, price, stock, category, brand, description
```

### 1.2 遇到的问题

```
问题 1：内存占用过高
- Redis 内存使用：10.2 GB
- 服务器内存：16 GB
- 内存使用率：63.75%
- 接近告警阈值（70%）

问题 2：成本压力
- 公司不批准扩容预算
- 需要在现有硬件上优化
- 目标：降低 50% 内存占用

问题 3：性能要求
- QPS：5000+
- P99 延迟：< 10ms
- 不能影响用户体验
```

### 1.3 初步分析

```bash
# 查看内存使用情况
127.0.0.1:6379> INFO memory
used_memory:10737418240  # 10 GB
used_memory_human:10.00G
used_memory_peak:10737418240
used_memory_peak_human:10.00G

# 查看键数量
127.0.0.1:6379> DBSIZE
(integer) 1500000  # 150 万个键

# 抽样检查编码类型
127.0.0.1:6379> OBJECT ENCODING user:1
"hashtable"  # ❌ 使用了 hashtable

127.0.0.1:6379> OBJECT ENCODING product:1
"hashtable"  # ❌ 使用了 hashtable
```

**问题根源**：所有 Hash 都使用了 hashtable 编码，内存占用过高

## 二、优化方案设计

### 2.1 数据分析

#### 用户信息分析

```bash
# 抽样 1000 个用户
127.0.0.1:6379> HGETALL user:12345
1) "id"
2) "12345"
3) "name"
4) "张三"
5) "email"
6) "zhangsan@example.com"
7) "phone"
8) "13800138000"
9) "city"
10) "北京"
11) "age"
12) "28"
13) "vip_level"
14) "2"
15) "created_at"
16) "2023-01-15"

# 统计结果
字段数量：8 个（< 512，符合 ziplist 条件）
最大值长度：23 字节（email，< 64，符合 ziplist 条件）
平均内存：612 字节/用户（hashtable）
```

#### 商品信息分析

```bash
# 抽样 1000 个商品
127.0.0.1:6379> HGETALL product:67890
1) "id"
2) "67890"
3) "name"
4) "iPhone 15 Pro Max 256GB"
5) "price"
6) "9999"
7) "stock"
8) "100"
9) "category"
10) "手机"
11) "brand"
12) "Apple"
13) "description"
14) "最新款 iPhone，支持 5G，A17 Pro 芯片，钛金属边框..."  # ❌ 超过 64 字节

# 统计结果
字段数量：7 个（< 512，符合 ziplist 条件）
最大值长度：description 平均 120 字节（❌ 超过 64 字节）
平均内存：856 字节/商品（hashtable）
```

### 2.2 优化策略

#### 策略 1：调整配置参数（用户信息）

```conf
# 用户信息完全符合 ziplist 条件
# 调整配置，强制使用 ziplist

hash-max-ziplist-entries 512  # 保持默认
hash-max-ziplist-value 64      # 保持默认
```

#### 策略 2：数据拆分（商品信息）

```
问题：description 字段过大，导致整个 Hash 使用 hashtable

解决方案：拆分数据
- product:{productId} → 基本信息（ziplist）
  - id, name, price, stock, category, brand
- product:{productId}:desc → 描述信息（String）
  - description
```

### 2.3 预期收益

```
用户信息优化：
- 优化前：100万 × 612字节 = 612 MB
- 优化后：100万 × 128字节 = 128 MB
- 节省：484 MB（79%）

商品信息优化：
- 优化前：50万 × 856字节 = 428 MB
- 优化后：50万 × (156字节 + 150字节) = 153 MB
- 节省：275 MB（64%）

总体优化：
- 优化前：10.2 GB
- 优化后：约 3.1 GB
- 节省：7.1 GB（70%）
```

## 三、优化实施

### 3.1 第一步：备份数据

```bash
# 1. 创建 RDB 快照
127.0.0.1:6379> SAVE
OK

# 2. 备份配置文件
cp /etc/redis/redis.conf /etc/redis/redis.conf.backup

# 3. 记录当前内存使用
127.0.0.1:6379> INFO memory > memory_before.txt
```

### 3.2 第二步：修改配置

```bash
# 编辑 redis.conf
vim /etc/redis/redis.conf

# 调整参数（已经是默认值，确认即可）
hash-max-ziplist-entries 512
hash-max-ziplist-value 64

# 重启 Redis
systemctl restart redis
```

### 3.3 第三步：数据迁移

#### 3.3.1 用户信息迁移（自动转换）

```bash
# 用户信息无需迁移，Redis 会自动使用 ziplist
# 但需要重新写入数据以触发编码转换

# 方案 1：使用 DUMP + RESTORE（推荐）
for key in $(redis-cli --scan --pattern "user:*"); do
    redis-cli --raw DUMP "$key" | redis-cli -x RESTORE "$key-new" 0
    redis-cli RENAME "$key-new" "$key"
done

# 方案 2：使用 HGETALL + HMSET
redis-cli --scan --pattern "user:*" | while read key; do
    redis-cli HGETALL "$key" | redis-cli -x HMSET "$key-new"
    redis-cli RENAME "$key-new" "$key"
done
```

#### 3.3.2 商品信息迁移（数据拆分）

编写迁移脚本：

```java
@Service
public class ProductMigrationService {
    
    @Autowired
    private StringRedisTemplate redisTemplate;
    
    public void migrateProducts() {
        // 1. 扫描所有商品键
        ScanOptions options = ScanOptions.scanOptions()
            .match("product:*")
            .count(100)
            .build();
        
        Cursor<String> cursor = redisTemplate.scan(options);
        
        int count = 0;
        while (cursor.hasNext()) {
            String key = cursor.next();
            
            // 跳过已经是描述键的
            if (key.endsWith(":desc")) {
                continue;
            }
            
            // 2. 获取所有字段
            Map<Object, Object> product = redisTemplate.opsForHash().entries(key);
            
            // 3. 提取 description
            String description = (String) product.remove("description");
            
            // 4. 保存基本信息（ziplist）
            redisTemplate.opsForHash().putAll(key + ":new", product);
            
            // 5. 保存描述信息（String）
            if (description != null) {
                redisTemplate.opsForValue().set(key + ":desc", description);
            }
            
            // 6. 重命名
            redisTemplate.rename(key + ":new", key);
            
            count++;
            if (count % 1000 == 0) {
                log.info("已迁移 {} 个商品", count);
            }
        }
        
        log.info("商品迁移完成，共 {} 个", count);
    }
}
```

### 3.4 第四步：验证效果

```bash
# 1. 检查编码类型
127.0.0.1:6379> OBJECT ENCODING user:1
"ziplist"  # ✅ 已转换为 ziplist

127.0.0.1:6379> OBJECT ENCODING product:1
"ziplist"  # ✅ 已转换为 ziplist

# 2. 检查内存使用
127.0.0.1:6379> MEMORY USAGE user:1
(integer) 128  # ✅ 从 612 降到 128

127.0.0.1:6379> MEMORY USAGE product:1
(integer) 156  # ✅ 从 856 降到 156

# 3. 检查总内存
127.0.0.1:6379> INFO memory
used_memory:3221225472  # 3 GB
used_memory_human:3.00G  # ✅ 从 10GB 降到 3GB
```

## 四、性能影响分析

### 4.1 性能测试

#### 测试 1：用户信息查询

```bash
# 优化前（hashtable）
redis-benchmark -t hget -n 100000 -d 100
====== HGET ======
  100000 requests completed in 1.20 seconds
  Requests per second: 83333.33
  Average latency: 0.012 ms

# 优化后（ziplist）
redis-benchmark -t hget -n 100000 -d 100
====== HGET ======
  100000 requests completed in 1.50 seconds
  Requests per second: 66666.67
  Average latency: 0.015 ms

性能下降：20%（可接受）
```

#### 测试 2：商品信息查询

```bash
# 优化前（hashtable，单次查询）
HGETALL product:1
耗时：0.02 ms

# 优化后（ziplist + String，两次查询）
HGETALL product:1
GET product:1:desc
耗时：0.03 ms

性能下降：50%（但绝对值很小，可接受）
```

### 4.2 实际业务影响

```
监控数据（优化后 7 天）：

QPS：
- 优化前：5200
- 优化后：5100
- 变化：-1.9%（在误差范围内）

P99 延迟：
- 优化前：8.5 ms
- 优化后：9.2 ms
- 变化：+0.7 ms（可接受）

P999 延迟：
- 优化前：15 ms
- 优化后：18 ms
- 变化：+3 ms（可接受）

结论：性能影响在可接受范围内
```

## 五、优化总结

### 5.1 优化成果

| 指标 | 优化前 | 优化后 | 改善 |
|------|--------|--------|------|
| **内存使用** | 10.2 GB | 3.0 GB | **-70%** |
| **用户信息内存** | 612 MB | 128 MB | **-79%** |
| **商品信息内存** | 428 MB | 153 MB | **-64%** |
| **QPS** | 5200 | 5100 | -1.9% |
| **P99 延迟** | 8.5 ms | 9.2 ms | +0.7 ms |

### 5.2 成本节省

```
硬件成本节省：
- 原计划：扩容到 32GB 内存
- 成本：约 ¥5000/年
- 实际：无需扩容
- 节省：¥5000/年

运维成本节省：
- 内存使用率：从 63% 降到 19%
- 告警频率：从每周 2 次降到 0 次
- 运维时间：节省约 20 小时/年
```

### 5.3 经验总结

#### 成功经验

1. **数据分析是关键**
   - 详细分析数据特征
   - 找出优化空间

2. **合理拆分数据**
   - 将大字段独立存储
   - 保持小对象使用 ziplist

3. **充分测试**
   - 在测试环境验证
   - 监控性能影响

4. **灰度发布**
   - 先迁移 10% 数据
   - 观察 24 小时
   - 逐步扩大范围

#### 注意事项

1. **备份数据**
   - 迁移前必须备份
   - 保留回滚方案

2. **监控告警**
   - 设置内存告警
   - 监控编码转换

3. **业务兼容**
   - 修改查询逻辑（商品描述）
   - 保持 API 兼容

4. **性能权衡**
   - 接受轻微性能下降
   - 换取大幅内存节省

## 六、进一步优化

### 6.1 持续监控

```bash
# 定期检查编码类型
redis-cli --scan --pattern "user:*" | head -100 | while read key; do
    echo "$key: $(redis-cli OBJECT ENCODING $key)"
done

# 监控内存使用趋势
redis-cli INFO memory | grep used_memory_human
```

### 6.2 自动化脚本

```bash
#!/bin/bash
# check_encoding.sh

# 检查 hashtable 编码的 Hash 键
redis-cli --scan --pattern "*" | while read key; do
    type=$(redis-cli TYPE $key)
    if [ "$type" = "hash" ]; then
        encoding=$(redis-cli OBJECT ENCODING $key)
        if [ "$encoding" = "hashtable" ]; then
            fields=$(redis-cli HLEN $key)
            if [ $fields -lt 100 ]; then
                echo "警告：$key 使用 hashtable，但只有 $fields 个字段"
            fi
        fi
    fi
done
```

### 6.3 未来规划

1. **定期审计**
   - 每月检查一次编码类型
   - 发现异常及时优化

2. **新业务规范**
   - 新增 Hash 必须评估编码类型
   - 优先使用 ziplist

3. **自动化工具**
   - 开发自动迁移工具
   - 集成到 CI/CD 流程

## 七、常见问题

### Q1：优化后性能下降怎么办？

```
A：分场景处理

场景 1：P99 延迟增加 < 5ms
→ 可接受，继续使用 ziplist

场景 2：P99 延迟增加 > 10ms
→ 考虑回滚或调整参数

场景 3：QPS 下降 > 10%
→ 回滚，重新评估方案
```

### Q2：如何判断是否适合 ziplist？

```
A：检查清单

✅ 字段数量 < 100
✅ 单个值 < 64 字节
✅ 读多写少
✅ QPS < 10000
✅ 内存紧张

满足 3 条以上 → 适合 ziplist
```

### Q3：迁移过程中出错怎么办？

```
A：回滚方案

1. 停止迁移脚本
2. 恢复配置文件
3. 重启 Redis
4. 恢复 RDB 快照
5. 验证数据完整性
```

### Q4：如何避免编码意外转换？

```
A：预防措施

1. 监控字段数量
   - 设置告警：字段数 > 400

2. 监控值大小
   - 设置告警：单个值 > 50 字节

3. 代码审查
   - 新增字段必须评估影响
```

## 八、总结

通过合理使用 ziplist 编码，我们成功将 Redis 内存从 **10GB 降到 3GB**，节省了 **70%** 的内存，避免了硬件扩容，节省了 **¥5000/年** 的成本。

**核心要点**：
- ✅ 数据分析是优化的基础
- ✅ 合理拆分数据可以兼顾内存和性能
- ✅ 充分测试和监控是成功的保障
- ✅ 接受合理的性能权衡

**适用场景**：
- 内存紧张，成本敏感
- 数据符合 ziplist 条件
- 可接受轻微性能下降
