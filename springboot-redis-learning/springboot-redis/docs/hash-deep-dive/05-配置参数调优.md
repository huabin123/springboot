# 配置参数调优

## 一、核心配置参数

### 1.1 hash-max-ziplist-entries

**作用**：控制 Hash 使用 ziplist 编码的最大字段数量

```conf
# redis.conf
hash-max-ziplist-entries 512  # 默认值
```

**含义**：
- 当 Hash 字段数量 < 512 时，使用 ziplist
- 当 Hash 字段数量 >= 512 时，转换为 hashtable

### 1.2 hash-max-ziplist-value

**作用**：控制 Hash 使用 ziplist 编码的最大值大小

```conf
# redis.conf
hash-max-ziplist-value 64  # 默认值（字节）
```

**含义**：
- 当所有值大小 < 64 字节时，使用 ziplist
- 当任一值大小 >= 64 字节时，转换为 hashtable

### 1.3 转换条件

```
ziplist → hashtable 转换条件（满足任一即转换）：

条件 1：字段数量 >= hash-max-ziplist-entries
条件 2：单个值大小 >= hash-max-ziplist-value

⚠️ 重要：转换是单向的，不可逆！
```

## 二、参数调优策略

### 2.1 场景 1：内存优化优先

**适用场景**：
- 内存紧张，成本敏感
- 对象字段数量较多（100-1000）
- 单个值较小（< 128 字节）
- 查询 QPS 不高（< 5000）

**推荐配置**：

```conf
# 激进的内存优化配置
hash-max-ziplist-entries 1024  # 提高到 1024
hash-max-ziplist-value 128     # 提高到 128
```

**效果预估**：

| 字段数 | 默认配置 | 优化配置 | 内存节省 |
|-------|---------|---------|---------|
| 100 | hashtable | ziplist | 80% |
| 500 | hashtable | ziplist | 82% |
| 800 | hashtable | ziplist | 83% |

**注意事项**：
- 字段数越多，查询性能下降越明显
- 建议 entries < 1024
- 建议 value < 256

### 2.2 场景 2：性能优化优先

**适用场景**：
- 查询 QPS 很高（> 10000）
- 需要极低延迟（P99 < 1ms）
- 内存充足
- 对象字段数量较多

**推荐配置**：

```conf
# 激进的性能优化配置
hash-max-ziplist-entries 128   # 降低到 128
hash-max-ziplist-value 32      # 降低到 32
```

**效果预估**：

| 字段数 | 默认配置 | 优化配置 | 性能提升 |
|-------|---------|---------|---------|
| 100 | ziplist | hashtable | 3-5倍 |
| 200 | ziplist | hashtable | 5-10倍 |
| 500 | hashtable | hashtable | 无变化 |

**注意事项**：
- 内存占用会显著增加
- 适合内存充足的场景

### 2.3 场景 3：平衡配置

**适用场景**：
- 内存和性能都需要兼顾
- 对象字段数量适中（50-200）
- 查询 QPS 适中（1000-5000）

**推荐配置**：

```conf
# 平衡的配置（默认值）
hash-max-ziplist-entries 512   # 保持默认
hash-max-ziplist-value 64      # 保持默认
```

**效果预估**：
- 大部分小对象使用 ziplist
- 大对象自动转换为 hashtable
- 内存和性能达到平衡

## 三、参数调优实战

### 3.1 步骤 1：数据分析

```bash
# 1. 统计字段数量分布
redis-cli --scan --pattern "user:*" | head -1000 | while read key; do
    redis-cli HLEN $key
done | sort -n | uniq -c

# 输出示例：
#  800 5    # 800 个键有 5 个字段
#  150 8    # 150 个键有 8 个字段
#   30 12   # 30 个键有 12 个字段
#   20 600  # 20 个键有 600 个字段

# 2. 统计值大小分布
redis-cli --scan --pattern "user:*" | head -100 | while read key; do
    redis-cli HGETALL $key | awk 'NR%2==0 {print length($0)}'
done | sort -n | uniq -c

# 输出示例：
#  500 10   # 500 个值大小为 10 字节
#  300 25   # 300 个值大小为 25 字节
#   50 80   # 50 个值大小为 80 字节
```

### 3.2 步骤 2：选择配置

根据数据分析结果选择配置：

```
分析结果：
- 95% 的键字段数 < 100
- 90% 的值大小 < 50 字节
- 5% 的键字段数 > 500

推荐配置：
hash-max-ziplist-entries 512  # 覆盖 95% 的键
hash-max-ziplist-value 64     # 覆盖 90% 的值

预期效果：
- 95% 的键使用 ziplist
- 5% 的键使用 hashtable
- 内存节省约 75%
```

### 3.3 步骤 3：测试验证

```bash
# 1. 在测试环境修改配置
vim /etc/redis/redis-test.conf
hash-max-ziplist-entries 512
hash-max-ziplist-value 64

# 2. 重启 Redis
systemctl restart redis-test

# 3. 导入测试数据
redis-cli --pipe < test_data.txt

# 4. 检查编码类型
redis-cli --scan --pattern "user:*" | head -100 | while read key; do
    echo "$key: $(redis-cli OBJECT ENCODING $key)"
done | sort | uniq -c

# 输出示例：
#   95 ziplist    # 95% 使用 ziplist
#    5 hashtable  # 5% 使用 hashtable

# 5. 性能测试
redis-benchmark -t hget,hset -n 100000 -d 100
```

### 3.4 步骤 4：灰度发布

```bash
# 1. 在生产环境的一台从库修改配置
vim /etc/redis/redis-slave1.conf
hash-max-ziplist-entries 512
hash-max-ziplist-value 64

# 2. 重启从库
systemctl restart redis-slave1

# 3. 观察 24 小时
# - 监控内存使用
# - 监控查询延迟
# - 监控错误日志

# 4. 如果正常，逐步推广到其他从库和主库
```

## 四、动态调整参数

### 4.1 运行时修改

```bash
# 1. 查看当前配置
127.0.0.1:6379> CONFIG GET hash-max-ziplist-entries
1) "hash-max-ziplist-entries"
2) "512"

127.0.0.1:6379> CONFIG GET hash-max-ziplist-value
1) "hash-max-ziplist-value"
2) "64"

# 2. 动态修改配置
127.0.0.1:6379> CONFIG SET hash-max-ziplist-entries 1024
OK

127.0.0.1:6379> CONFIG SET hash-max-ziplist-value 128
OK

# 3. 持久化配置（重启后生效）
127.0.0.1:6379> CONFIG REWRITE
OK
```

**注意事项**：
- 动态修改只影响新创建的 Hash
- 已存在的 Hash 不会自动转换
- 需要重新写入数据才能生效

### 4.2 触发编码转换

```bash
# 方法 1：使用 DUMP + RESTORE
redis-cli DUMP user:1 | redis-cli -x RESTORE user:1:new 0
redis-cli RENAME user:1:new user:1

# 方法 2：使用 HGETALL + HMSET
redis-cli HGETALL user:1 | redis-cli -x HMSET user:1:new
redis-cli RENAME user:1:new user:1

# 方法 3：批量处理
redis-cli --scan --pattern "user:*" | while read key; do
    redis-cli DUMP "$key" | redis-cli -x RESTORE "$key:new" 0
    redis-cli RENAME "$key:new" "$key"
done
```

## 五、监控与告警

### 5.1 监控指标

```bash
# 1. 监控编码类型分布
redis-cli --scan --pattern "*" | while read key; do
    type=$(redis-cli TYPE $key)
    if [ "$type" = "hash" ]; then
        encoding=$(redis-cli OBJECT ENCODING $key)
        echo $encoding
    fi
done | sort | uniq -c

# 输出示例：
#  95000 ziplist
#   5000 hashtable

# 2. 监控内存使用
redis-cli INFO memory | grep used_memory_human

# 3. 监控字段数量
redis-cli --scan --pattern "user:*" | while read key; do
    redis-cli HLEN $key
done | awk '{sum+=$1; count++} END {print "平均字段数:", sum/count}'
```

### 5.2 告警规则

```yaml
# Prometheus 告警规则示例
groups:
  - name: redis_hash_encoding
    rules:
      # 告警 1：hashtable 占比过高
      - alert: HighHashtableRatio
        expr: |
          (redis_hash_hashtable_count / redis_hash_total_count) > 0.2
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Redis hashtable 占比过高"
          description: "当前 hashtable 占比 {{ $value }}，建议优化配置"
      
      # 告警 2：字段数量接近阈值
      - alert: HashFieldCountNearLimit
        expr: |
          redis_hash_field_count > 400
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Hash 字段数量接近阈值"
          description: "键 {{ $labels.key }} 字段数量 {{ $value }}，接近 512 阈值"
      
      # 告警 3：值大小接近阈值
      - alert: HashValueSizeNearLimit
        expr: |
          redis_hash_value_size > 50
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Hash 值大小接近阈值"
          description: "键 {{ $labels.key }} 值大小 {{ $value }} 字节，接近 64 字节阈值"
```

## 六、常见问题

### Q1：修改配置后，已存在的 Hash 会自动转换吗？

```
A：不会自动转换

原因：
- Redis 不会主动重新编码已存在的数据
- 编码类型在创建时确定

解决方案：
1. 使用 DUMP + RESTORE 重新写入
2. 等待数据自然过期后重新创建
3. 编写脚本批量迁移
```

### Q2：如何选择合适的参数值？

```
A：基于数据分析

步骤：
1. 统计字段数量分布
2. 统计值大小分布
3. 选择覆盖 90% 数据的阈值
4. 测试验证
5. 灰度发布

示例：
- 90% 字段数 < 200 → entries = 256
- 90% 值大小 < 100 → value = 128
```

### Q3：参数设置过大会有什么问题？

```
A：性能下降

问题：
- ziplist 查询 O(N)，字段越多越慢
- 更新需要移动内存，字段越多越慢
- 可能触发连锁更新

建议：
- entries < 1024
- value < 256
- 根据实际 QPS 调整
```

### Q4：参数设置过小会有什么问题？

```
A：内存浪费

问题：
- 小对象也使用 hashtable
- 内存占用增加 5-10 倍
- 内存碎片增加

建议：
- entries >= 128
- value >= 32
- 除非内存非常充足
```

## 七、最佳实践

### 7.1 配置建议

| 场景 | entries | value | 说明 |
|------|---------|-------|------|
| **内存优先** | 1024 | 128 | 最大化内存节省 |
| **性能优先** | 128 | 32 | 最大化查询性能 |
| **平衡配置** | 512 | 64 | 默认值，适合大多数场景 |
| **小对象** | 256 | 64 | 字段少、值小 |
| **大对象** | 512 | 128 | 字段多、值大 |

### 7.2 调优流程

```
1. 数据分析
   ↓
2. 选择配置
   ↓
3. 测试环境验证
   ↓
4. 性能测试
   ↓
5. 灰度发布
   ↓
6. 监控观察
   ↓
7. 全量发布
   ↓
8. 持续监控
```

### 7.3 注意事项

1. **备份数据**
   - 修改配置前必须备份
   - 保留回滚方案

2. **充分测试**
   - 在测试环境验证
   - 性能测试必不可少

3. **灰度发布**
   - 先从库后主库
   - 观察 24 小时

4. **持续监控**
   - 监控编码类型
   - 监控内存使用
   - 监控查询性能

## 八、总结

### 8.1 核心要点

- ✅ 根据数据特征选择配置
- ✅ 内存优先 → 调大参数
- ✅ 性能优先 → 调小参数
- ✅ 充分测试和监控
- ⚠️ 修改配置不会自动转换已存在的数据

### 8.2 推荐配置

```conf
# 大多数场景推荐配置
hash-max-ziplist-entries 512  # 默认值
hash-max-ziplist-value 64     # 默认值

# 内存紧张场景
hash-max-ziplist-entries 1024
hash-max-ziplist-value 128

# 性能敏感场景
hash-max-ziplist-entries 256
hash-max-ziplist-value 32
```

### 8.3 调优收益

合理配置参数可以：
- 节省 60%-80% 内存
- 避免硬件扩容
- 降低运维成本
- 提升系统稳定性
